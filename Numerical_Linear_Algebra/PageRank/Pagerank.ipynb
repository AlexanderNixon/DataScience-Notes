{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import eig, norm, solve\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse import identity, diags, csr_matrix\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1: Solve the exercises 1,4 and 10 of Ref. [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Exercise 1. Suppose the people who own page 3 in the web of Figure 1 are infuriated by the fact that its importance score, computed using formula (1), is lower than the score of page 1. In an attempt to boost page 3’s score, they create a page 5 that links to page 3; page 3 also links to page 5. Does this boost page 3’s score above that of page 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "AX=\\lambda X \\rightarrow \\left ( A-\\lambda I_n \\right )X=0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous expression translates into solving the following system, where, given that we are interested in the eigenvector corresponding to the eigenvalue of 1, we substract 1 from the diagonal and equate to zero to solve through Gaussian elimination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\left(\n",
    "\\begin{array}{ccccc|c}\n",
    "-1&0&1/2&1/2&0&0 \\\\\n",
    "1/3&-1&0&0&0&0 \\\\\n",
    "1/3&1/2&-1&1/2&1&0\\\\\n",
    "1/3&1/2&0&-1&0&0\\\\\n",
    "0&0&1/2&0&-1&0\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first begin with changing of sign the first row and performing the following operations:\n",
    "\n",
    "\\begin{equation}\n",
    "\\left\\{\\begin{matrix}\n",
    "R2=R2-\\frac{1}{3}R1\\\\ \n",
    "R3=R3-\\frac{1}{3}R1\\\\ \n",
    "R4=R4-\\frac{1}{3}R1\n",
    "\\end{matrix}\\right.\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\left(\n",
    "\\begin{array}{ccccc|c}\n",
    "1&0&-1/2&-1/2&0&0 \\\\\n",
    "1/3&-1&0&0&0&0 \\\\\n",
    "1/3&1/2&-1&1/2&1&0\\\\\n",
    "1/3&1/2&0&-1&0&0\\\\\n",
    "0&0&1/2&0&-1&0\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\rightarrow\n",
    "\\left(\n",
    "\\begin{array}{ccccc|c}\n",
    "-1&0&-1/2&-1/2&0&0 \\\\\n",
    "0&-1&1/6&1/6&0&0 \\\\\n",
    "0&1/2&-5/6&2/3&1&0\\\\\n",
    "0&1/2&1/6&-5/6&0&0\\\\\n",
    "0&0&1/2&0&-1&0\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now focus on the second column, where changing the second equation of sign and using the second pivot we can reduce the system to:\n",
    "\n",
    "\\begin{equation}\n",
    "\\left\\{\\begin{matrix}\n",
    "R3=R3-\\frac{1}{2}R2\\\\ \n",
    "R4=R4-\\frac{1}{2}R2\n",
    "\\end{matrix}\\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\left(\n",
    "\\begin{array}{ccccc|c}\n",
    "-1&0&-1/2&-1/2&0&0 \\\\\n",
    "0&1&-1/6&-1/6&0&0 \\\\\n",
    "0&0&-3/4&3/4&1&0\\\\\n",
    "0&0&1/4&-3/4&0&0\\\\\n",
    "0&0&1/2&0&-1&0\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\rightarrow\n",
    "\\left(\n",
    "\\begin{array}{ccccc|c}\n",
    "-1&0&-1/2&-1/2&0&0 \\\\\n",
    "0&1&-1/6&-1/6&0&0 \\\\\n",
    "0&0&1&-1&-4/3&0\\\\\n",
    "0&0&1/4&-3/4&0&0\\\\\n",
    "0&0&1/2&0&-1&0\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now focus on the second column, where changing the third equation of sign and using the third pivot we can reduce the system to:\n",
    "\n",
    "\\begin{equation}\n",
    "\\left\\{\\begin{matrix}\n",
    "R1=R1+\\frac{1}{2}R3\\\\ \n",
    "R2=R2+\\frac{1}{6}R3\\\\\n",
    "R4=R4-\\frac{1}{4}R3\\\\\n",
    "R5=R5-\\frac{1}{2}R3\n",
    "\\end{matrix}\\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\left(\n",
    "\\begin{array}{ccccc|c}\n",
    "-1&0&0&-1&-2/3&0 \\\\\n",
    "0&1&0&-1/3&-2/9&0 \\\\\n",
    "0&0&1&-1&-4/3&0\\\\\n",
    "0&0&0&-1/2&1/3&0\\\\\n",
    "0&0&0&1/2&-1/3&0\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\rightarrow\n",
    "\\left(\n",
    "\\begin{array}{ccccc|c}\n",
    "-1&0&0&-1&-2/3&0 \\\\\n",
    "0&1&0&-1/3&-2/9&0 \\\\\n",
    "0&0&1&-1&-4/3&0\\\\\n",
    "0&0&0&1&-2/3&0\\\\\n",
    "0&0&0&1/2&-1/3&0\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now focus on the second column, where using the forth pivot we can reduce the system to:\n",
    "\n",
    "\\begin{equation}\n",
    "\\left\\{\\begin{matrix}\n",
    "R1=R1+R4\\\\ \n",
    "R2=R2+\\frac{1}{3}R4\\\\\n",
    "R3=R3+R4\\\\\n",
    "R5=R5-\\frac{1}{2}R4\n",
    "\\end{matrix}\\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\left(\n",
    "\\begin{array}{ccccc|c}\n",
    "-1&0&0&0&-4/3&0 \\\\\n",
    "0&1&0&0&-4/9&0 \\\\\n",
    "0&0&1&0&-2&0\\\\\n",
    "0&0&0&1&-2/3&0\\\\\n",
    "0&0&0&0&0&0\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now rewritting the equations from the resulting system, we can establish the following equalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\left\\{\\begin{matrix}\n",
    "x_1=\\frac{4}{3}\\\\ \n",
    "x_2=\\frac{4}{9}\\\\ \n",
    "x_3=2\\\\\n",
    "x_4=\\frac{2}{3}\\\\  \n",
    "\\end{matrix}\\right.\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding eigenvector is finally obtained by imposing that the norm 1 of the vector of scores is 1, this is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\left \\| x \\right \\|_1=\\sum_{i=1}^{n}x_i=1\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done by dividing alla element by the norm 1 of x, obtaining finally the scores as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{x}{\\left \\| x \\right \\|_1}=\\left\\{\\begin{matrix}\n",
    "x_1=\\frac{\\frac{4}{3}}{5.44}=0.244\\\\ \n",
    "x_2=\\frac{\\frac{4}{9}}{5.44}=0.081\\\\ \n",
    "x_3=\\frac{2}{5.44}=0.367\\\\\n",
    "x_4=\\frac{\\frac{2}{3}}{5.44}=0.122\\\\  \n",
    "x_5=\\frac{1}{5.44}=0.183\n",
    "\\end{matrix}\\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained result can rapidly be verified by solving the linear system ( i.e. the code forstrategy 1 ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.5         0.5         0.        ]\n",
      " [ 0.33333333  0.          0.          0.          0.        ]\n",
      " [ 0.33333333  0.5         0.          0.5         1.        ]\n",
      " [ 0.33333333  0.5         0.          0.          0.        ]\n",
      " [ 0.          0.          0.5         0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "A_1=np.array([[0,0,1.0/2,1.0/2,0],[1.0/3,0,0,0,0],[1.0/3,1.0/2,0,1.0/2,1],\n",
    "              [1.0/3,1.0/2,0,0,0],[0,0,1.0/2,0,0]])\n",
    "print A_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24484871,  0.08173462,  0.36722615,  0.12256106,  0.18362946])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=1e-3\n",
    "n=5\n",
    "B=identity(n)-(1-m)*A_1\n",
    "e=np.ones(n)\n",
    "x=spsolve(B,e)\n",
    "x/sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen the same result hasbeen obtained with only a few iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Exercise 4. In the web of Figure 1, remove the link from page 3 to page 1. In the resulting web, page 3 is now a dangling node. Set up the corresponding substochastic matrix and find its largest positive (Perron) eigenvalue. Find a nonnegative Perron eigenvector for this eigenvalue, and scale the vector so that its components sum to 1. Does the resulting ranking seem reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, as mentioned in the problem statement, the largest positive (Perron) eigenvalue has to be found. Thismis, given that the matrix has a dangling node it is not columns stochastic, and the largest eigenvalue has to be found, as it can not be asumed that it will be 1. To do so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "det\\left ( A-\\lambda I_n \\right )=0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\left|\n",
    "\\begin{array}{cccc}\n",
    "-\\lambda&0&0&1/2 \\\\\n",
    "1/3&-\\lambda&0&0\\\\\n",
    "1/3&1/2&-\\lambda&1/2\\\\\n",
    "1/3&1/2&0&-\\lambda\\\\\n",
    "\\end{array}\n",
    "\\right|\n",
    "=\\lambda \\left (-\\lambda^3 \\right) -1/2 \\left (-\\lambda^2/3 +\\lambda/6 \\right) =12\\lambda^4 -2\\lambda^2-\\lambda=0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the previous equation has the following roots:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{x}{\\left \\| x \\right \\|_1}=\\left\\{\n",
    "\\begin{matrix}\n",
    "x_1=0\\\\                                        \n",
    "x_2=0.56086\\\\ \n",
    "x_3=-0.28068+0.26395j\\\\ \n",
    "x_4=-0.28068-0.26395j\n",
    "\\end{matrix}\\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second eigenvalue, $x_2=0.56086$, is the one with higher magnitude, therefore it is its eigenvector that we are interested in obtaining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having reached to this point, the solution could be obtained be Gaussian elimination. Here below the final step having performed several steps of Gaussian elimination is shown. As it can be seen, even though the system has a solution, solving it by Gaussian elimination has lead to the trivial solution. However, knowing that the score vector must add up to 1, it can be seen that the solution can be obtained by assigning a non-zero value to $x_4$, that way, as shown further on we solve for the PR vector:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "(A|0)=\n",
    "\\left(\n",
    "\\begin{array}{cccc|c}\n",
    "1&0&0&-\\frac{25}{28}&0 \\\\\n",
    "0&1&0&-\\frac{625}{1176}&0 \\\\\n",
    "0&0&1&-\\frac{62525}{32928}&0\\\\\n",
    "0&0&0&1&0\\\\\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\rightarrow\n",
    "\\frac{x}{\\left \\| x \\right \\|_1}=\\left\\{\\begin{matrix}\n",
    "x_1=\\frac{\\frac{25}{28}}{\\left \\| x \\right \\|_1}=0.2065\\\\ \n",
    "x_2=\\frac{\\frac{625}{1176}}{\\left \\| x \\right \\|_1}=0.1229\\\\ \n",
    "x_3=\\frac{\\frac{62525}{32928}}{\\left \\| x \\right \\|_1}=0.4392\\\\\n",
    "x_4=\\frac{1}{\\left \\| x \\right \\|_1}=0.2313\n",
    "\\end{matrix}\\right.\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculations are verified below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20652884,  0.12293383,  0.43922503,  0.2313123 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=1\n",
    "x=np.array([c*25.0/28,c*625.0/1176,c*62525.0/32928 ,c])\n",
    "x/sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution can be verified directly solving the system as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1=0\n",
    "x2=0.5608695\n",
    "x3=-0.28068+0.26395j\n",
    "x4=-0.28068-0.26395j\n",
    "x=np.array([x1,x2,x3,x4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5608695 ,  0.        ,  0.        ,  0.5       ],\n",
       "       [ 0.33333333, -0.5608695 ,  0.        ,  0.        ],\n",
       "       [ 0.33333333,  0.5       , -0.5608695 ,  0.5       ],\n",
       "       [ 0.33333333,  0.5       ,  0.        , -0.5608695 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=np.array([[-x2,0,0,1.0/2],[1.0/3,-x2,0,0],[1.0/3,1.0/2,-x2,1.0/2],\n",
    "            [1.0/3,1.0/2,0,-x2]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eigv=solve(A,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20669151,  0.12232505,  0.43913074,  0.23185394])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(eigv/sum(eigv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Exercise 10. Suppose that A is the link matrix for a strongly connected web of n pages (any page can be reached from any other page by following a finite number of links). Show that dim(V1(A)) = 1 as follows. Let (Ak)ij denote the (i,j)-entry of Ak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show that\n",
    "\\begin{equation}\n",
    "(A^2)_{ij}=\\sum_{k=1}^na_{ik}a_{kj}>0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if page i can be reached from page j in exactly two steps, there must be some k, for which going from i $\\rightarrow$ k and then from k $\\rightarrow$ j (therefore two steps ) gives a non-zero result, therefore a connection exists, and therefore one of the terms in the sumation must be nonzero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show more generally that $(A^p)_{ij}$ > 0 if and only if page i can be reached from page j in exactly p steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having deduced the statement for reaching a node in two steps, this can be extended to p steps by using the same logic. This is, to reach i from page j in p steps, there must be a combination of p steps out of all possible combinations that is nonzero and therefore enables that node to be reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More precisely:\n",
    "\\begin{equation}\n",
    "(A^p)_{ij}=\\sum_{1\\leqslant l_1,...,l_{k-1}\\leqslant n}^{n} a_{il_1}a_{l_1l_2}...a_{k-1,j}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Argue that $(I+A+A^2 +···+A^p)_ij > 0$ if and only if page i can be reached from page j in p or fewer steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having shown that for for page i to be reached by page j in p steps, $(A^p)_{ij}>0$ must be satisfied, it also makes sense to state that it can also be reached in a minor amount of steps if for any $A^q$, for $q< p$ the condition is satisfied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explain why $I+A+A^2 +···+A^{n−1}$ is a positive matrix if the web is strongly\n",
    "connected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a web is strongly connected, it means that any node can be reached from any other node in a given number of steps. Therefore for all possible j's to i's, there must be a combination of steps ( therefore some $A^p$ ) through which the final node can be reached, which is to say that there must be a positive term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the last part (and Exercise 8) to show that $B = \\frac{1}{n} (I+A+A^2 +· · ·+A^{n−1})$ is positive and column-stochastic (and hence by Lemma 3, dim(V1(B)) = 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A is column stochastic, which can also be expressed as: $1^t A=1^t$, ans therefore expressing B as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$B = \\frac{1}{n} (I+A+A^2 +· · ·+A^{n−1}) = \\frac{1}{n} (1^t+...+1^t)=1^t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that B is also columns stochastic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show that if x ∈ V1(A), then x ∈ V1(B). Why does this imply that dim(V1(A))\n",
    "= 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nowing that $x ∈ V1(A)$, this is $Ax=x$ for some x, then this score vector from the eigenspace for the eigenvalue 1 from a column stochastic matrix A is also contained in B, given that, as it has already been shown, when A is column stochastic B also is column stochastic, hence it will also contain a maximum eigenvalue equal to one, and this eigenspace will have the same dimension, $V_1(A)=V_1(B)$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2: Implement the three previous algorithms to compute the PR vector. Use them for the examples in [1] to check they work properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All algorithms have been implemented taking advantage of the sparsity of the matrices to speed up the computations. The matrices from exercise one are used to test the correctness of the results for all cases.\n",
    "\n",
    "In all cases, it can be noticed that when the PR vector for the matrix with a a dangling node is obtained, i.e. the third matrix for all strategies in task 2, the result is somewhat deviated from the correct one obtained in task 1. The reason behind this is that here we approximate A with a matrix M, that modifies slightly the matrix, as the elements from the column which elements add up to 0 are divided by n. This effect is irrelevant for large matrices, as n will be very large, thus $\\frac{1}{n}\\approx 0$, but when the method is implemented on smaller matrices it gives a slightly different result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### 1. Solving a linear system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below solves the system directly and returns the PR vector. This algorithm however becomes computationally very expensive, as it involves inerting B, defined below, to solve for PR. This becomes more clear when larger matrices are used in strategy 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_system_solve(n,G,col,m=0.15):\n",
    "    index,c=np.unique(col,return_counts=True)\n",
    "    d=np.zeros(n)\n",
    "    d[np.array(map(int,index))]=1.0/c\n",
    "    B=identity(n)-(1-m)*G.dot(diags(d))\n",
    "    e=np.ones(n)\n",
    "    x=spsolve(B,-e)\n",
    "    return x/sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is tested hereunder for the matrices used task 1, showing that it is correctly implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0.  1.  1.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.24440379,  0.08265325,  0.36613802,  0.12356661,  0.18323832])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "row = np.array([0, 0, 1, 2, 2, 2, 2, 3, 3, 4])\n",
    "col = np.array([2, 3, 0, 0, 1, 3, 4, 0, 1, 2])\n",
    "data = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "G=csr_matrix((data, (row, col)), shape=(n, n))\n",
    "print G.toarray()\n",
    "linear_system_solve(n,G,m=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  1.]\n",
      " [ 1.  1.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.38586893,  0.12983675,  0.29018838,  0.19410594])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=4\n",
    "row = np.array([0,0, 1, 2, 2, 2, 3, 3])\n",
    "col = np.array([2,3, 0, 0, 1, 3, 0, 1])\n",
    "data = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "G=csr_matrix((data, (row, col)), shape=(n, n))\n",
    "print G.toarray()\n",
    "linear_system_solve(n,G,m=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  1.]\n",
      " [ 1.  1.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.21923755,  0.17523074,  0.35582792,  0.2497038 ])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=4\n",
    "d=np.zeros(n)\n",
    "row = np.array([0, 1, 2, 2, 2, 3, 3])\n",
    "col = np.array([3, 0, 0, 1, 3, 0, 1])\n",
    "data = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "G=csr_matrix((data, (row, col)), shape=(n, n))\n",
    "print G.toarray()\n",
    "linear_system_solve(n,G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### 2. Power method (adapted to PR computation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the algorithm for the second strategy, this is, the adapted PR computation.\n",
    "As specifiedin the exercise statement, the algorithm iterates until $\\left \\| x_{k+1}-x_k \\right \\|_\\infty < tol$, where tol has defined to be as an example 1e-8.\n",
    "\n",
    "An important detail taken into account for the computation, is that when when the product $ez^tx$ is performed, first $z^tx$ must be multiplied, as the result is a scalar, which can then be multiplied to e. Otherwise firstly a matrix is computed, and then multiplied by a vector instead, which in comparisson is highly inefficient. This fact supposes a massive difference when larger matrices are used, for instance lake the one in task 3.\n",
    "\n",
    "For the matrices under test, low values of m have been used, given that higher values give a larger deviation of the result for such small matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def power_method(n,G,col,m=0.15,tol=1e-8):\n",
    "    i=0\n",
    "    index,c=np.unique(col,return_counts=True)\n",
    "    d=np.zeros(n)\n",
    "    d[np.array(map(int,index))]=1.0/c\n",
    "    A=G.dot(diags(d))\n",
    "    e=np.ones(n)\n",
    "    x=np.ones(n)*(1.0/n)\n",
    "    z=np.ones(n)*(1.0/n)\n",
    "    z[np.array(map(int,index))]=(m/n)\n",
    "    while True:\n",
    "        x_aux=np.array((1-m)*A.dot(x)+np.dot(e,np.dot(z.T,x))).flatten()\n",
    "        if norm(x_aux-x,np.inf)<tol:\n",
    "            break\n",
    "        x=x_aux\n",
    "        i+=1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is tested hereunder for the matrices used task 1, showing that it is correctly implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix G used:\n",
      "[[ 0.  0.  1.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  1.]\n",
      " [ 1.  1.  0.  0.]]\n",
      "PR vector: [ 0.38697422  0.12911241  0.2903093   0.19360406]\n"
     ]
    }
   ],
   "source": [
    "n=4\n",
    "row = np.array([0,0, 1, 2, 2, 2, 3, 3])\n",
    "col = np.array([2,3, 0, 0, 1, 3, 0, 1])\n",
    "data = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "G=csr_matrix((data, (row, col)), shape=(n, n))\n",
    "print \"Matrix G used:\"\n",
    "print G.toarray()\n",
    "print \"PR vector:\", power_method(n,G,col,m=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix G used:\n",
      "[[ 0.  0.  1.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0.  1.  1.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]]\n",
      "PR vector: [ 0.24484871  0.08173462  0.36722614  0.12256106  0.18362946]\n"
     ]
    }
   ],
   "source": [
    "n=5\n",
    "row = np.array([0, 0, 1, 2, 2, 2, 2, 3, 3, 4])\n",
    "col = np.array([2, 3, 0, 0, 1, 3, 4, 0, 1, 2])\n",
    "data = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "G=csr_matrix((data, (row, col)), shape=(n, n))\n",
    "print \"Matrix G used:\"\n",
    "print G.toarray()\n",
    "print \"PR vector:\", power_method(n,G,col,m=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix G used:\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  1.]\n",
      " [ 1.  1.  0.  0.]]\n",
      "PR vector: [ 0.21651175  0.16501436  0.37103484  0.24743905]\n"
     ]
    }
   ],
   "source": [
    "n=4\n",
    "row = np.array([0, 1, 2, 2, 2, 3, 3])\n",
    "col = np.array([3, 0, 0, 1, 3, 0, 1])\n",
    "data = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "G=csr_matrix((data, (row, col)), shape=(n, n))\n",
    "print \"Matrix G used:\"\n",
    "print G.toarray()\n",
    "print \"PR vector:\", power_method(n,G,col,m=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### 3. Power method without storing the matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a function containing the third strategy has been defined. The algorithm provided in \"PRnmalgor.pdf\" has been strictly followed. In order to do so the set of indices $L_j$ corresponding to pages having a link with page j, and $c_j$ have been computed prior to the iteration loop. This has shown to result in a much higher efficiency and speed than obtaining these values inside the loop. The steps are briefly explained inside the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def power_method_no_storing(n,row,col,tol=1e-8,m=0.15):\n",
    "    \n",
    "    # Here cj and Lj are obtained. Dangling nodes are not\n",
    "    # taken into account, therefore zeros must be added\n",
    "    c_tmp = np.asarray((row).groupby(col).size())\n",
    "    L_tmp = np.asarray((row).groupby(col).groups.values())\n",
    "    L_tmp2 = itemgetter(*L_tmp)(np.asarray(row))\n",
    "\n",
    "    # Here the positions where dangling nodes exist are obtained, \n",
    "    # and stored in idx_dn\n",
    "    idx = np.unique(col)\n",
    "    idx2 = np.arange(idx[-1])\n",
    "    idx_dn = np.argwhere(np.in1d(idx2, np.intersect1d(idx2,idx))==False)\n",
    "\n",
    "    # Here the indexes with dangling nodes are added into c as zeros. \n",
    "    # NaNs have been added into L,\n",
    "    # given that the values do not matter, L[j] is not used \n",
    "    # in the if statement of the While.\n",
    "    c = np.insert(c_tmp,(idx_dn.ravel()-np.arange(len(idx_dn))),\n",
    "        [[0]] * len(idx_dn))\n",
    "    L = np.insert(L_tmp2,(idx_dn.ravel()-np.arange(len(idx_dn))),\n",
    "        [[np.nan]] * len(idx_dn))\n",
    "\n",
    "    xc=np.ones(n)*(1.0/n)\n",
    "    x=np.zeros(n)\n",
    "    iters=0\n",
    "\n",
    "    while(norm(x-xc,np.inf)>tol):\n",
    "        iters+=1\n",
    "        xc=x\n",
    "        x=np.zeros(n)\n",
    "        for j in range(0,n):\n",
    "            if c[j]==[0]:\n",
    "                x = x + xc[j]/n\n",
    "            else:\n",
    "                x[L[j]] = x[L[j]] + xc[j]/c[j]\n",
    "        x = (1-m)*x + m/n\n",
    "    return iters,x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is tested hereunder for the matrices used task 1, showing that it is correctly implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix G used:\n",
      "[[ 0.  0.  1.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  1.]\n",
      " [ 1.  1.  0.  0.]]\n",
      "The amount of iterations is: 1282\n",
      "The vector of scores x is: [ 0.38586795  0.12983642  0.29018764  0.19410545]\n"
     ]
    }
   ],
   "source": [
    "n=4\n",
    "row = pd.Series([0,0, 1, 2, 2, 2, 3, 3])\n",
    "col = pd.Series([2,3, 0, 0, 1, 3, 0, 1])\n",
    "data = pd.Series([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "G=csr_matrix((data, (row, col)), shape=(n, n))\n",
    "print \"Matrix G used:\"\n",
    "print G.toarray()\n",
    "iters,x = power_method_no_storing(n,row,col,m=1e-2)\n",
    "print \"The amount of iterations is:\", iters\n",
    "print \"The vector of scores x is:\", x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix G used:\n",
      "[[ 0.  0.  1.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0.  1.  1.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]]\n",
      "The amount of iterations is: 1276\n",
      "The vector of scores x is: [ 0.24440313  0.08265303  0.36613703  0.12356628  0.18323783]\n"
     ]
    }
   ],
   "source": [
    "n=5\n",
    "row = pd.Series([0, 0, 1, 2, 2, 2, 2, 3, 3, 4])\n",
    "col = pd.Series([2, 3, 0, 0, 1, 3, 4, 0, 1, 2])\n",
    "data = pd.Series([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "G=csr_matrix((data, (row, col)), shape=(n, n))\n",
    "print \"Matrix G used:\"\n",
    "print G.toarray()\n",
    "iters,x = power_method_no_storing(n,row,col,m=1e-2)\n",
    "print \"The amount of iterations is:\", iters\n",
    "print \"The vector of scores x is:\", x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix G used:\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  1.]\n",
      " [ 1.  1.  0.  0.]]\n",
      "The amount of iterations is: 1278\n",
      "The vector of scores x is: [ 0.21666411  0.16560869  0.37013956  0.24758499]\n"
     ]
    }
   ],
   "source": [
    "n=4\n",
    "row = pd.Series([0, 1, 2, 2, 2, 3, 3])\n",
    "col = pd.Series([3, 0, 0, 1, 3, 0, 1])\n",
    "data = pd.Series([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "G=csr_matrix((data, (row, col)), shape=(n, n))\n",
    "print \"Matrix G used:\"\n",
    "print G.toarray()\n",
    "iters,x = power_method_no_storing(n,row,col,m=1e-2)\n",
    "print \"The amount of iterations is:\", iters\n",
    "print \"The vector of scores x is:\", x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3: Download the \f",
    "le p2p-Gnutella30.mtx from the Sparse Matrix collection [3] Then use the previous methods to compute the PR vector. Report the results obtained. Inves- tigate the role of tol in the computation and the components of the PR vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the specified matrix is downloaded. The first 54 rows are skipped as they contain no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G=pd.read_table(\"p2p-Gnutella30.mtx\",sep=\" \",skiprows=54).as_matrix()\n",
    "row = G[:,0]-1\n",
    "col = G[:,1]-1\n",
    "data=np.ones(len(row))\n",
    "n=int(col[-1]+1)\n",
    "G=csr_matrix((data, (row, col)), shape=(n, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the PR vector is computed using the three defined strategies. As it can be seen all algorithm return the same PR vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### 1. Solving a linear system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, solving the linear system in strategy 1 results highly inefficient even though sparse matrices are used. The algorithm takes 140 s to calculate the PR vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computational time elapsed is: 171.015712\n",
      "The vector of scores x is: [  1.32691841e-04   4.42088107e-06   6.58669412e-05 ...,   4.42088107e-06\n",
      "   4.42088107e-06   4.42088107e-06]\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "x = linear_system_solve(n,G,col)\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print \"The computational time elapsed is:\", time_elapsed\n",
    "print \"The vector of scores x is:\", x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### 2. Power method (adapted to PR computation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is clearly the fastest of all. As previously mentioned, performing the products in the right order makes a huge difference in efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computational time elapsed is: 0.112508\n",
      "The vector of scores x is: [  1.32691886e-04   4.42088114e-06   6.58669215e-05 ...,   4.42088114e-06\n",
      "   4.42088114e-06   4.42088114e-06]\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "x = power_method(n,G,col)\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print \"The computational time elapsed is:\", time_elapsed\n",
    "print \"The vector of scores x is:\", x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### 3. Power method without storing the matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third method as shown is obviously not as fast as the second one, but it presents a clear advantage not requireing to store the matrices, this is, all operationds are performed through $L_j$ and $c_j$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G=pd.read_table(\"p2p-Gnutella30.mtx\",sep=\" \",skiprows=54)\n",
    "row = G.ix[:,0]-1\n",
    "col = G.ix[:,1]-1\n",
    "n = col.iloc[-1]+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the third strategy is used to obtain the PR vector for a tolerance of $1e^{-8}$. Later on the effect of the tolerance is analysed in more detail. In this case the answer is obtained in 15 s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computational time elapsed is: 14.929948\n",
      "The amount of iterations is: 67\n",
      "The vector of scores x is: [  1.32690167e-04   4.42087525e-06   6.58663903e-05 ...,   4.42087525e-06\n",
      "   4.42087525e-06   4.42087525e-06]\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "iters,x = power_method_no_storing(n,row,col,m=0.15,tol=1e-8)\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print \"The computational time elapsed is:\", time_elapsed\n",
    "print \"The amount of iterations is:\", iters\n",
    "print \"The vector of scores x is:\", x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the algorithm is analysed in more detail. The amount of iterations and computational times are displayed further down for a tolerance from $1e^{-1}$ up to $1e^{-13}$.\n",
    "\n",
    "As it can be noticed, the PR vector converges to a constant value, with a precision of $1e^{-8}·1e^{-6}=1e^{-14}$, which is the amount of decimals displayed on screen for values of the order $e^{-6}$, from the 13th iteration, thus a tolerance of $1e^{-13}$.\n",
    "\n",
    "It can also be observed that until a $tol=1e^{-6}$ the resulting PR vector does not approach the correct one. The reson behind this is that, for the original chosen x and auxiliary xc vector, where xc is used to check the convergence, the infinity norm $\\left \\| x_{k+1}-x_k \\right \\|_\\infty$ is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7261327081402323e-05"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xc=np.ones(n)*(1.0/n)\n",
    "x=np.zeros(n)\n",
    "norm(x-xc,np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the tolerance must be higher than $1e^{-6}$ due to the construction of the problem. \n",
    "\n",
    "The rate of convergence of the power method depends on the ratio between the two largest eigenvalues, this is $\\frac{|\\lambda_1|}{|\\lambda_2|}$. The rate of convergence of this method hence is linear. This is shown in the following plot, where as it can be seen, the increasment of the time elapsed is linear for increments of the tolerance.\n",
    "\n",
    "The rate of convergence with strategy 3 has also been analyzed for different tolerances. As expected, the lower the tolerance the higher the amount of iterations to reach the condition, and therefore the higher computational time. The following plot shows the increasment of the computational time in terms of the tolerances under test. A similar behaviour has been observed regarding strategy 2, mantaining the clearly lower computational time to solve for the PR vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGFCAYAAAC7YVotAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM99Bws3hEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11672df10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "line1,=plt.plot(k,time_elapsed,'b')\n",
    "plt.xlabel('$k$, $(tol=1e^{-k})$', fontsize=13)\n",
    "plt.ylabel('time_elapsed (s)', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iterations with tol=1e-1 in 0.161s\n",
      "PR vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\n",
      "0 iterations with tol=1e-2 in 0.144s\n",
      "PR vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\n",
      "0 iterations with tol=1e-3 in 0.198s\n",
      "PR vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\n",
      "0 iterations with tol=1e-4 in 0.150s\n",
      "PR vector: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\n",
      "1 iterations with tol=1e-5 in 0.401s\n",
      "PR vector: [  4.08919906e-06   4.08919906e-06   4.08919906e-06 ...,   4.08919906e-06\n",
      "   4.08919906e-06   4.08919906e-06]\n",
      "\n",
      "39 iterations with tol=1e-6 in 8.098s\n",
      "PR vector: [  1.32533358e-04   4.42033072e-06   6.58147800e-05 ...,   4.42033072e-06\n",
      "   4.42033072e-06   4.42033072e-06]\n",
      "\n",
      "53 iterations with tol=1e-7 in 10.937s\n",
      "PR vector: [  1.32675553e-04   4.42082451e-06   6.58615806e-05 ...,   4.42082451e-06\n",
      "   4.42082451e-06   4.42082451e-06]\n",
      "\n",
      "67 iterations with tol=1e-8 in 13.891s\n",
      "PR vector: [  1.32690167e-04   4.42087525e-06   6.58663903e-05 ...,   4.42087525e-06\n",
      "   4.42087525e-06   4.42087525e-06]\n",
      "\n",
      "81 iterations with tol=1e-9 in 16.518s\n",
      "PR vector: [  1.32691669e-04   4.42088047e-06   6.58668846e-05 ...,   4.42088047e-06\n",
      "   4.42088047e-06   4.42088047e-06]\n",
      "\n",
      "95 iterations with tol=1e-10 in 19.430s\n",
      "PR vector: [  1.32691823e-04   4.42088101e-06   6.58669354e-05 ...,   4.42088101e-06\n",
      "   4.42088101e-06   4.42088101e-06]\n",
      "\n",
      "110 iterations with tol=1e-11 in 22.541s\n",
      "PR vector: [  1.32691839e-04   4.42088106e-06   6.58669407e-05 ...,   4.42088106e-06\n",
      "   4.42088106e-06   4.42088106e-06]\n",
      "\n",
      "124 iterations with tol=1e-12 in 25.814s\n",
      "PR vector: [  1.32691841e-04   4.42088107e-06   6.58669412e-05 ...,   4.42088107e-06\n",
      "   4.42088107e-06   4.42088107e-06]\n",
      "\n",
      "138 iterations with tol=1e-13 in 28.616s\n",
      "PR vector: [  1.32691841e-04   4.42088107e-06   6.58669412e-05 ...,   4.42088107e-06\n",
      "   4.42088107e-06   4.42088107e-06]\n",
      "\n",
      "152 iterations with tol=1e-14 in 30.964s\n",
      "PR vector: [  1.32691841e-04   4.42088107e-06   6.58669412e-05 ...,   4.42088107e-06\n",
      "   4.42088107e-06   4.42088107e-06]\n",
      "\n",
      "166 iterations with tol=1e-15 in 33.784s\n",
      "PR vector: [  1.32691841e-04   4.42088107e-06   6.58669412e-05 ...,   4.42088107e-06\n",
      "   4.42088107e-06   4.42088107e-06]\n",
      "\n",
      "180 iterations with tol=1e-16 in 37.073s\n",
      "PR vector: [  1.32691841e-04   4.42088107e-06   6.58669412e-05 ...,   4.42088107e-06\n",
      "   4.42088107e-06   4.42088107e-06]\n",
      "\n",
      "194 iterations with tol=1e-17 in 40.166s\n",
      "PR vector: [  1.32691841e-04   4.42088107e-06   6.58669412e-05 ...,   4.42088107e-06\n",
      "   4.42088107e-06   4.42088107e-06]\n",
      "\n",
      "211 iterations with tol=1e-18 in 46.882s\n",
      "PR vector: [  1.32691841e-04   4.42088107e-06   6.58669412e-05 ...,   4.42088107e-06\n",
      "   4.42088107e-06   4.42088107e-06]\n",
      "\n",
      "242 iterations with tol=1e-19 in 50.045s\n",
      "PR vector: [  1.32691841e-04   4.42088107e-06   6.58669412e-05 ...,   4.42088107e-06\n",
      "   4.42088107e-06   4.42088107e-06]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "k=np.arange(1.0,20.0)\n",
    "tolerance=1*10**(-k)\n",
    "time_elapsed=np.zeros(len(k))\n",
    "for tol in tolerance:\n",
    "    time_start = time.clock()\n",
    "    iter,x = power_method_no_storing(n,row,col,tol)\n",
    "    time_elapsed[i] = (time.clock() - time_start)\n",
    "    print \"%d iterations with tol=1e-%d in %.3fs\" % (iter,k[i],time_elapsed[i])\n",
    "    print \"PR vector:\", x\n",
    "    print\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Discuss (no implementation re-quired) which are the possible strategies to deal with a larger webpage network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important drawback of the power method converges very slowly when the dominat eigenvalues have weak relative separation. However, the power method converges quite fast and gives a very good approximation of the eigenvector corresponding to the largest eigenvalue.\n",
    "\n",
    "Other alternatives exist for the case when we are dealing with very large matrices. This is the case of the Lanczos Iteration. This method gives at the end of every step a tri-diagonal matrix whose extreme eigenvalues approximatie the extreme eigenvalues of the original matrix. Under suitable initial conditions, the tridiagnoal matrix at the $n^{th}$ step has the same eigenvalues and the eigenvectors of the original matrix.\n",
    "\n",
    "The clear advantage, is that being the matrix tri-diagonal, the eigendecomposition is easily performed with other method, such as the power method.\n",
    "It is proved, that as long as $\\lambda_1$ is much larger than $\\lambda_2$, the Lanczos method converges much faster than the power method."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
