{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Àlex Escolà"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <h1> Jester Online Joke Recommender System </h1>\n",
    "\n",
    "    - <h4> Traditional Neiborhood Collaborative Filtering </h4>\n",
    "    In this first section, a matrix of similarity between all users is firstly defined. The Pearson correlation is used to define this similarity between users. Given that the matrix is symmetric, the main functions defined until a prediction for each test rating is obtained, only work with the lower triangular part of the matrix for computational time purposes. Having obbtained a similarity between all users  several prediction functions are tested in order to obtain an estimate of each rating in the test split, which will be later compared with the real value. The rating estimation in the user-user case is obtained as an average of the ratings of the k most similar users to the user in question times their similarity, obtained from the similarity matrix.\n",
    "    \n",
    "    The same process is repeated but defining an item-item similarity matrix. The process is very similar, but the prediction is performed by looking through similar items to predict a rating for a new item, instead of looking at similar users. Specifically, as before, the rating is estimated through the top k similar items. Results in this section show to be slightly better.\n",
    "    - <h4> Graph-Based recommender system </h4>\n",
    "    In this section a User-Item graph is built for each user independently using the Networkx library, from which the page rank is obtained and used as a measure of similarity. More detaliled in the section.\n",
    "    - <h4>  Content-Based recommender </h4>\n",
    "    In order to obtain the a measure of similarity between jokes, the process implemented here is as follows:\n",
    "        - All jokes are modelled by several topics using LDA\n",
    "        - The resulting vector of probabilites of the jokes belonging to each topic are obtained\n",
    "        - These vectors are used to obtain similarity measures between the jokes, taking the Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h3> Data preprocessing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following sections 1.000 samples from the original dataset are used, given that 20.000 reuquires a lot of computational time, and the result however does not vary significantly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('data/jester/jester-data-1.xls',header=None)\n",
    "df2 = pd.read_excel('data/jester/jester-data-2.xls',header=None)\n",
    "df3 = pd.read_excel('data/jester/jester-data-3.xls',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2,df3])\n",
    "df.index = range(len(df))\n",
    "#df = df.drop([0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>-7.82</td>\n",
       "      <td>8.79</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>-8.16</td>\n",
       "      <td>-7.52</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>-9.85</td>\n",
       "      <td>4.17</td>\n",
       "      <td>-8.98</td>\n",
       "      <td>...</td>\n",
       "      <td>2.82</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>-5.63</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4.08</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>6.36</td>\n",
       "      <td>4.37</td>\n",
       "      <td>-2.38</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-5.34</td>\n",
       "      <td>8.88</td>\n",
       "      <td>...</td>\n",
       "      <td>2.82</td>\n",
       "      <td>-4.95</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>7.86</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-4.32</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>9.03</td>\n",
       "      <td>9.27</td>\n",
       "      <td>9.03</td>\n",
       "      <td>9.27</td>\n",
       "      <td>99.00</td>\n",
       "      <td>...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>9.08</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>99.00</td>\n",
       "      <td>8.35</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>8.16</td>\n",
       "      <td>-2.82</td>\n",
       "      <td>6.21</td>\n",
       "      <td>99.00</td>\n",
       "      <td>...</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>8.50</td>\n",
       "      <td>4.61</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>-5.39</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.04</td>\n",
       "      <td>4.61</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.58</td>\n",
       "      <td>4.27</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.11</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4     5     6     7     8      9    ...    \\\n",
       "0   74  -7.82   8.79  -9.66  -8.16 -7.52 -8.50 -9.85  4.17  -8.98  ...     \n",
       "1  100   4.08  -0.29   6.36   4.37 -2.38 -9.66 -0.73 -5.34   8.88  ...     \n",
       "2   49  99.00  99.00  99.00  99.00  9.03  9.27  9.03  9.27  99.00  ...     \n",
       "3   48  99.00   8.35  99.00  99.00  1.80  8.16 -2.82  6.21  99.00  ...     \n",
       "4   91   8.50   4.61  -4.17  -5.39  1.36  1.60  7.04  4.61  -0.44  ...     \n",
       "\n",
       "     91     92     93     94     95     96     97     98     99     100  \n",
       "0   2.82  99.00  99.00  99.00  99.00  99.00  -5.63  99.00  99.00  99.00  \n",
       "1   2.82  -4.95  -0.29   7.86  -0.19  -2.14   3.06   0.34  -4.32   1.07  \n",
       "2  99.00  99.00  99.00   9.08  99.00  99.00  99.00  99.00  99.00  99.00  \n",
       "3  99.00  99.00  99.00   0.53  99.00  99.00  99.00  99.00  99.00  99.00  \n",
       "4   5.19   5.58   4.27   5.19   5.73   1.55   3.11   6.55   1.80   1.60  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a subsample datset of 20.000 samples\n",
    "df = df.sample(1000)\n",
    "\n",
    "# Divide the data into training and test set\n",
    "training = []\n",
    "test = []\n",
    "\n",
    "training = pd.DataFrame(index=df.index,columns=['items','#items'])\n",
    "test = pd.DataFrame(index=df.index,columns=['items','#items'])\n",
    "\n",
    "random.seed(47)\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    row = row[1:]\n",
    "    l = row[row <11]   \n",
    "    training_indexes = random.sample(l.index,int(0.75*(len(l))))\n",
    "    test_indexes = list(set(l.index) - set(training_indexes))\n",
    "    test['items'].ix[index] = test_indexes\n",
    "    test['#items'].ix[index] = len(test_indexes)\n",
    "    training['items'].ix[index] = training_indexes\n",
    "    training['#items'].ix[index] = len(training_indexes)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items</th>\n",
       "      <th>#items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54311</th>\n",
       "      <td>[18, 20, 70, 17, 63, 57, 5, 50, 46, 7, 13, 27,...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72458</th>\n",
       "      <td>[35, 16, 31, 19, 68, 5, 18, 32, 27, 20, 77, 13...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38730</th>\n",
       "      <td>[18, 46, 61, 64, 57, 15, 49, 50, 39, 42, 94, 4...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44417</th>\n",
       "      <td>[70, 49, 15, 65, 13, 68, 50, 22, 25, 18, 5, 11...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61433</th>\n",
       "      <td>[27, 38, 82, 55, 7, 17, 18, 32, 15, 13, 8, 67,...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   items #items\n",
       "54311  [18, 20, 70, 17, 63, 57, 5, 50, 46, 7, 13, 27,...     16\n",
       "72458  [35, 16, 31, 19, 68, 5, 18, 32, 27, 20, 77, 13...     19\n",
       "38730  [18, 46, 61, 64, 57, 15, 49, 50, 39, 42, 94, 4...     53\n",
       "44417  [70, 49, 15, 65, 13, 68, 50, 22, 25, 18, 5, 11...     38\n",
       "61433  [27, 38, 82, 55, 7, 17, 18, 32, 15, 13, 8, 67,...     14"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h3> Collaborative: Rating prediction though the similarity between users using Pearson Correlation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Pearson correlation between all users is calculated, resulting in a symmetric matrix. For this reason and in order to save computing time only the lower triangular part of the matrix is calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pearson = pd.DataFrame(index=training.index,columns=training.index)\n",
    "cont = 1\n",
    "for user1 in training.index:\n",
    "    for user2 in training.index[cont:]:\n",
    "        items1 = training['items'].loc[user1]\n",
    "        items2 = training['items'].loc[user2]\n",
    "        n_inters = set(items1).intersection(items2)\n",
    "        Pearson[user1][user2]=pearsonr(df.loc[user1],df.loc[user2])[0]\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50718</th>\n",
       "      <th>3722</th>\n",
       "      <th>42825</th>\n",
       "      <th>53055</th>\n",
       "      <th>61686</th>\n",
       "      <th>30845</th>\n",
       "      <th>58555</th>\n",
       "      <th>51496</th>\n",
       "      <th>2845</th>\n",
       "      <th>40671</th>\n",
       "      <th>...</th>\n",
       "      <th>58068</th>\n",
       "      <th>13889</th>\n",
       "      <th>51600</th>\n",
       "      <th>50801</th>\n",
       "      <th>65963</th>\n",
       "      <th>31193</th>\n",
       "      <th>15081</th>\n",
       "      <th>43462</th>\n",
       "      <th>54697</th>\n",
       "      <th>48399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50718</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>0.41699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42825</th>\n",
       "      <td>-0.00914689</td>\n",
       "      <td>-0.0311717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53055</th>\n",
       "      <td>0.574231</td>\n",
       "      <td>0.327561</td>\n",
       "      <td>0.029006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61686</th>\n",
       "      <td>0.546881</td>\n",
       "      <td>0.241821</td>\n",
       "      <td>-0.0523102</td>\n",
       "      <td>0.594919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            50718      3722       42825     53055 61686 30845 58555 51496  \\\n",
       "50718         NaN        NaN        NaN       NaN   NaN   NaN   NaN   NaN   \n",
       "3722      0.41699        NaN        NaN       NaN   NaN   NaN   NaN   NaN   \n",
       "42825 -0.00914689 -0.0311717        NaN       NaN   NaN   NaN   NaN   NaN   \n",
       "53055    0.574231   0.327561   0.029006       NaN   NaN   NaN   NaN   NaN   \n",
       "61686    0.546881   0.241821 -0.0523102  0.594919   NaN   NaN   NaN   NaN   \n",
       "\n",
       "      2845  40671  ...  58068 13889 51600 50801 65963 31193 15081 43462 54697  \\\n",
       "50718   NaN   NaN  ...    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3722    NaN   NaN  ...    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "42825   NaN   NaN  ...    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "53055   NaN   NaN  ...    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "61686   NaN   NaN  ...    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "      48399  \n",
       "50718   NaN  \n",
       "3722    NaN  \n",
       "42825   NaN  \n",
       "53055   NaN  \n",
       "61686   NaN  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pearson.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function selects for a specific user, all users which having rated the same item, have the highest Pearson correlation with this user. This function is called within the predict fuction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar(user, item, Pearson, training, k=10):\n",
    "    users_rated_item = [idx for idx in training.index if item in training['items'].loc[idx]]\n",
    "    y = Pearson[user][Pearson[user].notnull()]\n",
    "    x = Pearson.ix[user][Pearson.ix[user].notnull()]\n",
    "    all_users = pd.concat([x,y], axis = 0)\n",
    "    users_with_rating = all_users * all_users.index.isin(users_rated_item)\n",
    "    sort = users_with_rating.iloc[users_with_rating.argsort()][::-1][:k]\n",
    "    return sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695      0.592028\n",
       "48875    0.518501\n",
       "880      0.491167\n",
       "39462    0.456271\n",
       "39018    0.412335\n",
       "47376    0.365912\n",
       "40613    0.363519\n",
       "16572    0.355471\n",
       "7644     0.337809\n",
       "19659    0.329439\n",
       "Name: 50718, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(50718, 1, Pearson, training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow are three different versions of prediction functions based on the similarity among the most similar users. These take into account the most similar users in order to predict the rating of this  user on a specific item.\n",
    "\n",
    "The users who's ratings will be predicted are thoes within the test splint of the original dataset, in order to perform accuracy metrics further on. \n",
    "\n",
    "These ratings will be further on used in order to create a \"prediction matrix\", which will contain the ratings of all test elements, and will be then compared to the actual test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first prediction function, the standart method is implemented for predicting new user ratings from the similarity among other users is shown bellow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\hat{r}_{u,j}=\\frac{\\sum_{v \\in{P_u(j)}}{sim(u,v)\\cdot r_{v,j}}}{\\sum_{v \\in{P_u(j)}}{sim(u,v)}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_standart(user, item, Pearson, training, k=10):\n",
    "    similars = most_similar(user, item, Pearson, training, k)\n",
    "    numerator = [None]*len(similars)\n",
    "    boolean = [None]*len(similars)\n",
    "    for SimilarUser,similarity,i in zip(similars.index, similars.values, range(len(similars))):\n",
    "        rating = df.ix[SimilarUser][item] \n",
    "        boolean[i] = rating < 11\n",
    "        numerator[i] = rating * similarity if boolean[i] else 0\n",
    "    return sum(numerator)/sum(similars.values * boolean) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following prediction function has also been implemented, which as an addition to the previous one, it also takes into account the different scales in the ratings, or the bias in different user rating behaviours:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\hat{r}_{u,j}=\\bar{r}_u + \\frac{\\sum_{v \\in{P_u(j)}}{sim(u,v)\\cdot(r_{v,j}-\\bar{r}_v})}{\\sum_{v \\in{P_u(j)}}{sim(u,v)}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_rating_bias(user, item, Pearson, training, k=10):\n",
    "    similars = most_similar(user, item, Pearson, training, k)\n",
    "    numerator = [None]*len(similars)\n",
    "    boolean = [None]*len(similars)\n",
    "    for SimilarUser,similarity,i in zip(similars.index, similars.values, range(len(similars))):\n",
    "        mean_rv = np.mean(df.ix[SimilarUser][df.ix[SimilarUser] != 99.00])\n",
    "        rating = df.ix[SimilarUser][item] - mean_rv\n",
    "        boolean[i] = rating < 11\n",
    "        numerator[i] = rating * similarity if boolean[i] else 0\n",
    "        mean_ru = np.mean(df.ix[user][df.ix[user] != 99.00])\n",
    "    return (sum(numerator)/sum(similars.values * boolean)) + mean_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This estimator is similar to the latter, but also takes into ccount the standart deviation of the user ratings. This allow to compensate from the variance of the ratings from user to user, having this way a normalized rating for each user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\hat{r}_{u,j}=\\bar{r}_u + \\sigma _u \\frac{\\sum_{v \\in{P_u(j)}}{sim(u,v)\\cdot z_{v,j}}}{\\sum_{v \\in{P_u(j)}}{\\left | sim(u,v)\\right |}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_rating_bias_std(user, item, Pearson, training, k=10):\n",
    "    similars = most_similar(user, item, Pearson, training, k)\n",
    "    numerator = [None]*len(similars)\n",
    "    boolean = [None]*len(similars)\n",
    "    for SimilarUser,similarity,i in zip(similars.index, similars.values, range(len(similars))):\n",
    "        mean_rv = np.mean(df.ix[SimilarUser][df.ix[SimilarUser] != 99.00])\n",
    "        std_rv = np.std(df.ix[SimilarUser][df.ix[SimilarUser] != 99.00])\n",
    "        rating = (df.ix[SimilarUser][item] - mean_rv)/std_rv\n",
    "        boolean[i] = rating < 11\n",
    "        numerator[i] = rating * similarity if boolean[i] else 0\n",
    "        mean_ru = np.mean(df.ix[user][df.ix[user] != 99.00])\n",
    "        std_ru = np.std(df.ix[user][df.ix[user] != 99.00])\n",
    "    return (sum(numerator)/sum(abs(similars.values * boolean)))*std_ru + mean_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prediction matrix: \n",
    "\n",
    "    Here a matrix if the original matrix dimentions is generated, where a predicted rating is calculated for all users and each item in the test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predition_matrix(prediction_function, test, similarity_mtx, training):\n",
    "    PredMat = pd.DataFrame(index = test.index, columns = range(101))\n",
    "    for user in test.index:\n",
    "        for item in test.loc[user]['items']:\n",
    "            PredMat[item][user] = prediction_function(user, item, similarity_mtx, training)\n",
    "    return PredMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the following funtion is defined, which will return the Mean Absolute Error, and it will receive as an input the different prediction matrices obtained though the different prediction methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mae(PredMat):\n",
    "    mae = 0.\n",
    "    for user in PredMat.index:\n",
    "        predicts = PredMat.loc[user][PredMat.loc[user].notnull()]\n",
    "        df_values = df.loc[user][predicts.index]\n",
    "        mae += np.mean(abs(predicts - df_values))\n",
    "    return mae / len (PredMat.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Results using standart rating prediction  function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_mat_rating_standart = predition_matrix(predict_standart, test, Pearson, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50718</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.71654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.509791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.27847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.19155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.227044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42825</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.48023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.16772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.01805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.49796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.98365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53055</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61686</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1        2    3    4    5        6        7         8    9   ...   \\\n",
       "50718  NaN  NaN      NaN  NaN  NaN  NaN      NaN -3.71654       NaN  NaN ...    \n",
       "3722   NaN  NaN -2.27847  NaN  NaN  NaN  2.19155      NaN  0.227044  NaN ...    \n",
       "42825  NaN  NaN      NaN  NaN  NaN  NaN      NaN  1.48023       NaN  NaN ...    \n",
       "53055  NaN  NaN      NaN  NaN  NaN  NaN      NaN      NaN       NaN  NaN ...    \n",
       "61686  NaN  NaN      NaN  NaN  NaN  NaN      NaN      NaN       NaN  NaN ...    \n",
       "\n",
       "       91       92        93       94   95        96   97       98   99   100  \n",
       "50718  NaN      NaN       NaN      NaN  NaN -0.509791  NaN      NaN  NaN  NaN  \n",
       "3722   NaN      NaN       NaN      NaN  NaN       NaN  NaN      NaN  NaN  NaN  \n",
       "42825  NaN  4.16772       NaN  2.01805  NaN   4.49796  NaN  3.98365  NaN  NaN  \n",
       "53055  NaN      NaN       NaN      NaN  NaN       NaN  NaN      NaN  NaN  NaN  \n",
       "61686  NaN      NaN  0.500709      NaN  NaN       NaN  NaN      NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mat_rating_standart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.077\n",
      "NMAE: 0.204\n"
     ]
    }
   ],
   "source": [
    "mae_rating_standart = mae(pred_mat_rating_standart)\n",
    "print \"MAE: {}\".format(round(mae_rating_standart,3))\n",
    "print \"NMAE: {}\".format(round(mae_rating_standart/20,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Results using the rating prediction \"with bias\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_mat_rating_bias = predition_matrix(predict_rating_bias, test, Pearson, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50718</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.47072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.56866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.25875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.03517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42825</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.56512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.08296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.29587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.83984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53055</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61686</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.799581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1        2    3    4    5        6        7        8    9   ...   \\\n",
       "50718  NaN  NaN      NaN  NaN  NaN  NaN      NaN -4.47072      NaN  NaN ...    \n",
       "3722   NaN  NaN -3.25875  NaN  NaN  NaN  1.10671      NaN -1.03517  NaN ...    \n",
       "42825  NaN  NaN      NaN  NaN  NaN  NaN      NaN -1.56512      NaN  NaN ...    \n",
       "53055  NaN  NaN      NaN  NaN  NaN  NaN      NaN      NaN      NaN  NaN ...    \n",
       "61686  NaN  NaN      NaN  NaN  NaN  NaN      NaN      NaN      NaN  NaN ...    \n",
       "\n",
       "       91       92        93       94   95       96   97       98   99   100  \n",
       "50718  NaN      NaN       NaN      NaN  NaN -3.56866  NaN      NaN  NaN  NaN  \n",
       "3722   NaN      NaN       NaN      NaN  NaN      NaN  NaN      NaN  NaN  NaN  \n",
       "42825  NaN  2.08296       NaN  0.29587  NaN   2.2159  NaN  1.83984  NaN  NaN  \n",
       "53055  NaN      NaN       NaN      NaN  NaN      NaN  NaN      NaN  NaN  NaN  \n",
       "61686  NaN      NaN  0.799581      NaN  NaN      NaN  NaN      NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mat_rating_bias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.377\n",
      "NMAE: 0.169\n"
     ]
    }
   ],
   "source": [
    "mae_rating_bias = mae(pred_mat_rating_bias)\n",
    "print \"MAE: {}\".format(round(mae_rating_bias,3))\n",
    "print \"NMAE: {}\".format(round(mae_rating_bias/20,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Results using the rating prediction \"with bias and std\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_mat_rating_bias_std = predition_matrix(predict_rating_bias_std, test, Pearson, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50718</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.75975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.16134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.54243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.14088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.37988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42825</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.19687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.10448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.29535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.82874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53055</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61686</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1        2    3    4    5        6        7        8    9   ...   \\\n",
       "50718  NaN  NaN      NaN  NaN  NaN  NaN      NaN -3.75975      NaN  NaN ...    \n",
       "3722   NaN  NaN -3.54243  NaN  NaN  NaN  1.14088      NaN -1.37988  NaN ...    \n",
       "42825  NaN  NaN      NaN  NaN  NaN  NaN      NaN -2.19687      NaN  NaN ...    \n",
       "53055  NaN  NaN      NaN  NaN  NaN  NaN      NaN      NaN      NaN  NaN ...    \n",
       "61686  NaN  NaN      NaN  NaN  NaN  NaN      NaN      NaN      NaN  NaN ...    \n",
       "\n",
       "       91       92       93        94   95       96   97       98   99   100  \n",
       "50718  NaN      NaN      NaN       NaN  NaN -3.16134  NaN      NaN  NaN  NaN  \n",
       "3722   NaN      NaN      NaN       NaN  NaN      NaN  NaN      NaN  NaN  NaN  \n",
       "42825  NaN  2.10448      NaN  0.108869  NaN  2.29535  NaN  1.82874  NaN  NaN  \n",
       "53055  NaN      NaN      NaN       NaN  NaN      NaN  NaN      NaN  NaN  NaN  \n",
       "61686  NaN      NaN  1.10479       NaN  NaN      NaN  NaN      NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mat_rating_bias_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.326\n",
      "NMAE: 0.166\n"
     ]
    }
   ],
   "source": [
    "mae_rating_bias_std = mae(pred_mat_rating_bias_std)\n",
    "print \"MAE: {}\".format(round(mae_rating_bias_std,3))\n",
    "print \"NMAE: {}\".format(round(mae_rating_bias_std/20,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h3> Collaborative: Rating prediction through the similarity between items using the Pearson Correlation </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, given that the prediction will be based on the similarity measured between items, in order to simplify further operations the training-test splits are performed on portions of sets of users who have rated each item. Also this way there will be the certainty that all items have several ratings, for when lower datasets are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Divide the data into training and test set\n",
    "training_items = []\n",
    "test_items = []\n",
    "\n",
    "training_items = pd.DataFrame(index=df.columns,columns=['users'])[1:]\n",
    "test_items = pd.DataFrame(index=df.columns,columns=['users'])[1:]\n",
    "\n",
    "random.seed(47)\n",
    "\n",
    "for index,row in df.transpose()[1:].iterrows():\n",
    "    row = row[1:]\n",
    "    l = row[row <11]   \n",
    "    training_indexes = random.sample(l.index,int(0.75*(len(l))))\n",
    "    test_indexes = list(set(l.index) - set(training_indexes))\n",
    "    test_items['users'].ix[index] = test_indexes\n",
    "    training_items['users'].ix[index] = training_indexes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[45496, 7736, 34957, 23436, 32535, 17767, 1912...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[12316, 40598, 26954, 10143, 37723, 46273, 483...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[22614, 4040, 41830, 26609, 27523, 35409, 4742...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[21426, 40799, 4240, 7503, 44196, 45420, 26080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[72078, 28243, 60633, 63020, 41085, 29371, 454...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               users\n",
       "1  [45496, 7736, 34957, 23436, 32535, 17767, 1912...\n",
       "2  [12316, 40598, 26954, 10143, 37723, 46273, 483...\n",
       "3  [22614, 4040, 41830, 26609, 27523, 35409, 4742...\n",
       "4  [21426, 40799, 4240, 7503, 44196, 45420, 26080...\n",
       "5  [72078, 28243, 60633, 63020, 41085, 29371, 454..."
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Pearson correlation matrix between items is defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Pearson_items = pd.DataFrame(index=training_items.index, columns=training_items.index)\n",
    "cont = 1\n",
    "for item1 in training_items.index:\n",
    "    for item2 in training_items.index[cont:]:\n",
    "        users1 = training_items['users'].loc[item1]\n",
    "        users2 = training_items['users'].loc[item2]\n",
    "        n_inters = set(users1).intersection(users2)\n",
    "        Pearson_items[item1][item2]=pearsonr(df.transpose().loc[item1],df.transpose().loc[item2])[0]\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.883079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.938265</td>\n",
       "      <td>0.873756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.912433</td>\n",
       "      <td>0.835149</td>\n",
       "      <td>0.937821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0110715</td>\n",
       "      <td>-0.0049216</td>\n",
       "      <td>-0.0173057</td>\n",
       "      <td>-0.0224777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1          2          3          4    5    6    7    8    9    10   \\\n",
       "1        NaN        NaN        NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2   0.883079        NaN        NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3   0.938265   0.873756        NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4   0.912433   0.835149   0.937821        NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "5  0.0110715 -0.0049216 -0.0173057 -0.0224777  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "  ...   91   92   93   94   95   96   97   98   99   100  \n",
       "1 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "5 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pearson_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to before, we want to obtaina list of \"top k most similar\" items in this case, which will be used in the prediciton functions to obtain the rating of a new item based on the most similar items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar_items(item, user, Pearson, training, k=10):\n",
    "    items_rated_by_same_user = [idx for idx in training.index if user in training['users'].loc[idx]]\n",
    "    y = Pearson[item][Pearson[item].notnull()]\n",
    "    x = Pearson.ix[item][Pearson.ix[item].notnull()]\n",
    "    all_items = pd.concat([x,y], axis = 0)\n",
    "    items_with_rating = all_items * all_items.index.isin(items_rated_by_same_user)\n",
    "    sort = items_with_rating.iloc[items_with_rating.argsort()][::-1][:k]\n",
    "    return sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.883079\n",
       "3     0.873756\n",
       "10    0.864833\n",
       "23    0.860456\n",
       "33    0.858797\n",
       "30    0.853744\n",
       "25    0.849792\n",
       "24    0.849499\n",
       "6      0.84623\n",
       "4     0.835149\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_items(2,45496,Pearson_items, training_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several prediction functions are also tested in this case, in this case the standart prediction method, and the normalized rating prediction method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_standart_item_based(user, item, Pearson, training, k=10):\n",
    "    similar_items = most_similar_items(item, user, Pearson, training)\n",
    "    numerator = [None]*len(similar_items)\n",
    "    boolean = [None]*len(similar_items)\n",
    "    for SimilarItem,similarity,i in zip(similar_items.index, similar_items.values, range(len(similar_items))):\n",
    "        rating = df.transpose().ix[SimilarItem][user] \n",
    "        boolean[i] = rating < 11\n",
    "        numerator[i] = rating * similarity if boolean[i] else 0\n",
    "    return sum(numerator)/sum(similar_items.values * boolean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_rating_bias_std_item_based(user, item, Pearson, training, k=10):\n",
    "    similar_items = most_similar_items(item, user, Pearson, training)\n",
    "    numerator = [None]*len(similar_items)\n",
    "    boolean = [None]*len(similar_items)\n",
    "    df_t = df.transpose()\n",
    "    for SimilarItem,similarity,i in zip(similar_items.index, similar_items.values, range(len(similar_items))):\n",
    "        mean_rv = np.mean(df_t.ix[SimilarItem][df_t.ix[SimilarItem] != 99.00])\n",
    "        std_rv = np.std(df_t.ix[SimilarItem][df_t.ix[SimilarItem] != 99.00])\n",
    "        rating = (df_t.ix[SimilarItem][user] - mean_rv)/std_rv\n",
    "        boolean[i] = rating < 11\n",
    "        numerator[i] = rating * similarity if boolean[i] else 0\n",
    "        mean_ru = np.mean(df_t.ix[item][df_t.ix[item] != 99.00])\n",
    "        std_ru = np.std(df_t.ix[item][df_t.ix[item] != 99.00])\n",
    "    return (sum(numerator)/sum(abs(similar_items.values * boolean)))*std_ru + mean_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predition_matrix_item_based(prediction_function, test, similarity_mtx, training):\n",
    "    \n",
    "    # Prediction matrix columns only with the users that appear in the test split\n",
    "    unique_users = np.unique(list(chain.from_iterable(test['users'].tolist())))\n",
    "    \n",
    "    PredMat = pd.DataFrame(index = test.index, columns = unique_users)\n",
    "    for item in test.index[:96]:\n",
    "        for user in test.loc[item]['users']:\n",
    "            PredMat[user][item] = prediction_function(user, item, similarity_mtx, training)\n",
    "    return PredMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mae_item_based(PredMat):\n",
    "    mae = 0.\n",
    "    for user in PredMat.transpose().index:\n",
    "        predicts = PredMat.transpose().loc[user][PredMat.transpose().loc[user].notnull()]\n",
    "        df_values = df.loc[user][predicts.index]\n",
    "        mae += np.mean(abs(predicts - df_values))\n",
    "    return mae / len (PredMat.transpose().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions of the test split obtained through the standart prediction function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_mat_item_based_standart = predition_matrix_item_based(predict_standart_item_based, test_items, Pearson_items, training_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>209</th>\n",
       "      <th>241</th>\n",
       "      <th>245</th>\n",
       "      <th>270</th>\n",
       "      <th>272</th>\n",
       "      <th>511</th>\n",
       "      <th>542</th>\n",
       "      <th>614</th>\n",
       "      <th>626</th>\n",
       "      <th>695</th>\n",
       "      <th>...</th>\n",
       "      <th>72930</th>\n",
       "      <th>73014</th>\n",
       "      <th>73071</th>\n",
       "      <th>73079</th>\n",
       "      <th>73096</th>\n",
       "      <th>73202</th>\n",
       "      <th>73256</th>\n",
       "      <th>73288</th>\n",
       "      <th>73322</th>\n",
       "      <th>73415</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.91439</td>\n",
       "      <td>-0.163414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.91533</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.81399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.13351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0975623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.33523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.12175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.29473</td>\n",
       "      <td>5.20917</td>\n",
       "      <td>0.27836</td>\n",
       "      <td>0.981683</td>\n",
       "      <td>3.16564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.10646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.78748</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     209      241        245       270      272   511   542   614      626    \\\n",
       "1      NaN  6.91439  -0.163414       NaN      NaN   NaN   NaN   NaN      NaN   \n",
       "2      NaN      NaN    1.81399       NaN      NaN   NaN   NaN   NaN      NaN   \n",
       "3      NaN      NaN -0.0975623       NaN      NaN   NaN   NaN   NaN      NaN   \n",
       "4      NaN      NaN        NaN       NaN      NaN   NaN   NaN   NaN -2.12175   \n",
       "5  8.29473  5.20917    0.27836  0.981683  3.16564   NaN   NaN   NaN      NaN   \n",
       "\n",
       "     695     ...    72930   73014 73071 73079 73096    73202 73256 73288  \\\n",
       "1  3.91533   ...      NaN     NaN   NaN   NaN   NaN      NaN   NaN   NaN   \n",
       "2      NaN   ...      NaN     NaN   NaN   NaN   NaN      NaN   NaN   NaN   \n",
       "3      NaN   ...      NaN     NaN   NaN   NaN   NaN      NaN   NaN   NaN   \n",
       "4      NaN   ...      NaN     NaN   NaN   NaN   NaN      NaN   NaN   NaN   \n",
       "5      NaN   ...      NaN  2.8799   NaN   NaN   NaN -1.10646   NaN   NaN   \n",
       "\n",
       "     73322    73415  \n",
       "1      NaN      NaN  \n",
       "2      NaN  7.13351  \n",
       "3      NaN  6.33523  \n",
       "4      NaN      NaN  \n",
       "5 -2.78748      NaN  \n",
       "\n",
       "[5 rows x 999 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mat_item_based_standart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And through the normalized rating prediction function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_mat_item_based_bias_std = predition_matrix_item_based(predict_rating_bias_std_item_based, test_items, Pearson_items, training_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>209</th>\n",
       "      <th>241</th>\n",
       "      <th>245</th>\n",
       "      <th>270</th>\n",
       "      <th>272</th>\n",
       "      <th>511</th>\n",
       "      <th>542</th>\n",
       "      <th>614</th>\n",
       "      <th>626</th>\n",
       "      <th>695</th>\n",
       "      <th>...</th>\n",
       "      <th>72930</th>\n",
       "      <th>73014</th>\n",
       "      <th>73071</th>\n",
       "      <th>73079</th>\n",
       "      <th>73096</th>\n",
       "      <th>73202</th>\n",
       "      <th>73256</th>\n",
       "      <th>73288</th>\n",
       "      <th>73322</th>\n",
       "      <th>73415</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.04855</td>\n",
       "      <td>2.58153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00247</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.80175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.68966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.4049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.3716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.86118</td>\n",
       "      <td>6.72701</td>\n",
       "      <td>1.6324</td>\n",
       "      <td>1.88806</td>\n",
       "      <td>4.7026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.12169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.278095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.41028</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     209      241      245      270     272   511   542   614     626    \\\n",
       "1      NaN  9.04855  2.58153      NaN     NaN   NaN   NaN   NaN     NaN   \n",
       "2      NaN      NaN  1.80175      NaN     NaN   NaN   NaN   NaN     NaN   \n",
       "3      NaN      NaN  1.68966      NaN     NaN   NaN   NaN   NaN     NaN   \n",
       "4      NaN      NaN      NaN      NaN     NaN   NaN   NaN   NaN -2.3716   \n",
       "5  9.86118  6.72701   1.6324  1.88806  4.7026   NaN   NaN   NaN     NaN   \n",
       "\n",
       "     695     ...   72930    73014 73071 73079 73096     73202 73256 73288  \\\n",
       "1  4.00247   ...     NaN      NaN   NaN   NaN   NaN       NaN   NaN   NaN   \n",
       "2      NaN   ...     NaN      NaN   NaN   NaN   NaN       NaN   NaN   NaN   \n",
       "3      NaN   ...     NaN      NaN   NaN   NaN   NaN       NaN   NaN   NaN   \n",
       "4      NaN   ...     NaN      NaN   NaN   NaN   NaN       NaN   NaN   NaN   \n",
       "5      NaN   ...     NaN  4.12169   NaN   NaN   NaN  0.278095   NaN   NaN   \n",
       "\n",
       "     73322   73415  \n",
       "1      NaN     NaN  \n",
       "2      NaN  8.1486  \n",
       "3      NaN  7.4049  \n",
       "4      NaN     NaN  \n",
       "5 -1.41028     NaN  \n",
       "\n",
       "[5 rows x 999 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mat_item_based_bias_std.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, the recomendation based on an item-item similarity matrix, sensibly improves results obtained using a user-user similarity matrix for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results using the standart prediction function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.407\n",
      "NMAE: 0.17\n"
     ]
    }
   ],
   "source": [
    "mae_item_based_standart = mae_item_based(pred_mat_item_based_standart)\n",
    "print \"MAE: {}\".format(round(mae_item_based_standart,3))\n",
    "print \"NMAE: {}\".format(round(mae_item_based_standart/20,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And using the latter prediciton function, which takes into account possible biases in rating behaviours and also the standart deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.326\n",
      "NMAE: 0.166\n"
     ]
    }
   ],
   "source": [
    "mae_item_based_bias_std = mae_item_based(pred_mat_item_based_bias_std)\n",
    "print \"MAE: {}\".format(round(mae_item_based_bias_std,3))\n",
    "print \"NMAE: {}\".format(round(mae_item_based_bias_std/20,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h3> Collaborative: Similarity between users using personalized Page Rank </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section a User-Item graph is defined for each user individually, through which the page rank is obtained and used as a similarity measure between the different users. The top ranked user are used as the most similar ones, and taken into account for the rating estimation.\n",
    "\n",
    "Firstly a general graph is defined with the all the interactions of all users to their corresponding items, where each weight is set to be the corresponding rating, divided by the amount of ratings the corresponding user has made.\n",
    "\n",
    "Afterwoods this same original graph is called for each user individually and links of weight 1/n are assigned between all items and all other items (avoiding items that are already connected) and also from each item to all other users, except for the user in question, to which a rating of 1/n is added to the already existing rating, personalizing this way the graph for each user.\n",
    "\n",
    "\n",
    "Networkx is used to both define the graph and calculate the Page rank on each graph that is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items</th>\n",
       "      <th>#items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31787</th>\n",
       "      <td>[31, 35, 36, 29, 39, 96, 7, 69, 5, 13, 19, 56,...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24149</th>\n",
       "      <td>[39, 54, 25, 63, 85, 89, 80, 21, 69, 71, 55, 6...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28035</th>\n",
       "      <td>[53, 56, 1, 8, 81, 88, 32, 96, 93, 22, 6, 11, ...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7856</th>\n",
       "      <td>[94, 51, 30, 93, 52, 35, 11, 87, 79, 68, 33, 3...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46938</th>\n",
       "      <td>[44, 64, 35, 30, 56, 27, 33, 28, 58, 20, 52, 8...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   items #items\n",
       "31787  [31, 35, 36, 29, 39, 96, 7, 69, 5, 13, 19, 56,...     33\n",
       "24149  [39, 54, 25, 63, 85, 89, 80, 21, 69, 71, 55, 6...     75\n",
       "28035  [53, 56, 1, 8, 81, 88, 32, 96, 93, 22, 6, 11, ...     75\n",
       "7856   [94, 51, 30, 93, 52, 35, 11, 87, 79, 68, 33, 3...     75\n",
       "46938  [44, 64, 35, 30, 56, 27, 33, 28, 58, 20, 52, 8...     53"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_original = nx.DiGraph()\n",
    "g_original.add_nodes_from(training.index, bipartite=0)\n",
    "g_original.add_nodes_from(range(1,100), bipartite=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for user in training.index:\n",
    "    n = len(training.ix[user]['items'])\n",
    "    for item in training.ix[user][0]:\n",
    "        weight = df.ix[user].loc[item]\n",
    "        g_original.add_weighted_edges_from([(user,item,weight/n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def page_rank(g, user, training, df):\n",
    "    \n",
    "    add_link_from_item = 1\n",
    "    n = len(training.ix[user]['items'])\n",
    "    for item in training.ix[user][0]:\n",
    "        \n",
    "        # Links of the user in question are redefined as the already existing ones + 1/n\n",
    "        weight = df.ix[user].loc[item]\n",
    "        g.add_weighted_edges_from([(user,item,weight/n + 1./n)])\n",
    "        \n",
    "        # Set of links to avoid dangling nodes\n",
    "        # Links of weight 1/n from item in question to all users( except thoes previously added)\n",
    "        set_of_users_to_link = [(item, users, 1./n) for users in training.index if users != user]\n",
    "        g.add_weighted_edges_from(set_of_users_to_link)\n",
    "        \n",
    "        # Links of weight 1/n from item in question to all other items (excluding existing links)\n",
    "        range_items_to_link = range(add_link_from_item,100)\n",
    "        set_of_items_to_link = [(item, i, 1./n) for i in range_items_to_link]\n",
    "        g.add_weighted_edges_from(set_of_items_to_link)\n",
    "        add_link_from_item += 1\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function builds the similarity matrix by calling the previous function for each user, and therefore building a User-Item graph for each user,and obtaining a similarity measure. \n",
    "\n",
    "After the graph (g) is returned from the previus function, the pagerank builtin function from Networkx is called (nx.pagerank(g)), and each Rank-User_2 couple returned for each User_1, are used to define a similarity of User_1 with User_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similarity_mtx = pd.DataFrame(index=training.index,columns=training.index)\n",
    "for user1 in training.index:\n",
    "    g = page_rank(g_original, user1, training, df)\n",
    "    pr = nx.pagerank(g)\n",
    "    [similarity_mtx.set_value(user1, user2, rat) for user2, rat in zip(pr.keys(), pr.values()) if user2 > 100]           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction matrix is built in this case the same way as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_mat_rating_bias_page_rank = predition_matrix(predict_rating_bias, test, similarity_mtx, training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are very similar to thoes obtained using a collaborative filtering approach. The main issue in this case on why results are not improved through this method, is that page rank techniques tend to work better when there is more sparsity in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.488\n",
      "NMAE: 0.174\n"
     ]
    }
   ],
   "source": [
    "mae_page_rank = mae(pred_mat_rating_bias_page_rank)\n",
    "print \"MAE: {}\".format(round(mae_page_rank,3))\n",
    "print \"NMAE: {}\".format(round(mae_page_rank/20,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <h3> Content Based </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import lda\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Obtaining the jokes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jokes_read = [None]*100\n",
    "for i in range(1,100):\n",
    "    files = \"jokes/init{}.html\".format(i)\n",
    "    f = codecs.open(files, 'r').read()\n",
    "    jokes_read[i] = re.findall ( '-->\\n(.*?)\\n<!--', f, re.DOTALL)\n",
    "del jokes_read[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A man visits the doctor. The doctor says \"I have bad news for you.You have\\ncancer and Alzheimer\\'s disease\". <P>\\nThe man replies \"Well,thank God I don\\'t have cancer!\"',\n",
       " 'This couple had an excellent relationship going until one day he came home\\nfrom work to find his girlfriend packing. He asked her why she was leaving him\\nand she told him that she had heard awful things about him. \\n<P>\\n\"What could they possibly have said to make you move out?\" \\n<P>\\n\"They told me that you were a pedophile.\" \\n<P>\\nHe replied, \"That\\'s an awfully big word for a ten year old.\" ',\n",
       " \"Q. What's 200 feet long and has 4 teeth? <P>\\n\\nA. The front row at a Willie Nelson Concert.\",\n",
       " \"Q. What's the difference between a man and a toilet? \\n<P>\\nA. A toilet doesn't follow you around after you use it.\",\n",
       " \"Q.\\tWhat's O. J. Simpson's Internet address? <P>\\nA.\\tSlash, slash, backslash, slash, slash, escape.\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes = [item for sublist in jokes_read for item in sublist]\n",
    "[joke for joke in jokes[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "In order to obtain the a measure of similarity between jokes, the process implemented here is as follows:\n",
    "- All jokes are modelled by several topics using LDA\n",
    "- The resulting vector of probabilites of the jokes belonging to each topic are obtained\n",
    "- These vectors are used to obtain similarity measures between the jokes, by using the Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def topic_modeling(x, n_topics, n_iter):\n",
    "    vectorizer =  CountVectorizer(analyzer='word', ngram_range=(1,1), min_df = 0, stop_words = [\"english\"])\n",
    "    matrix =  vectorizer.fit_transform(x)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    model = lda.LDA(n_topics = n_topics, n_iter = n_iter, random_state=1)\n",
    "    model.fit(matrix.astype(int))\n",
    "    topic_word = model.topic_word_\n",
    "    doc_topic = model.doc_topic_\n",
    "    return model, feature_names, topic_word, doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 98\n",
      "INFO:lda:vocab_size: 1550\n",
      "INFO:lda:n_words: 5415\n",
      "INFO:lda:n_topics: 10\n",
      "INFO:lda:n_iter: 100\n",
      "INFO:lda:<0> log likelihood: -56209\n",
      "INFO:lda:<10> log likelihood: -42401\n",
      "INFO:lda:<20> log likelihood: -41224\n",
      "INFO:lda:<30> log likelihood: -40797\n",
      "INFO:lda:<40> log likelihood: -40462\n",
      "INFO:lda:<50> log likelihood: -40327\n",
      "INFO:lda:<60> log likelihood: -40289\n",
      "INFO:lda:<70> log likelihood: -40189\n",
      "INFO:lda:<80> log likelihood: -39929\n",
      "INFO:lda:<90> log likelihood: -39955\n",
      "INFO:lda:<99> log likelihood: -39709\n"
     ]
    }
   ],
   "source": [
    "lda_model, feature_names, topic_word, doc_topic = topic_modeling(jokes, n_topics=10, n_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the top_modeling function, a vector of probabilities of each joke of belonging to each topic (in this case 10 topics) are obtained, which will be used as a measure of similarity between jokes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke: How many feminists does it take to screw in a light bulb?<P>\n",
      "That's not funny.\n",
      "\n",
      "Doc_topic:[ 0.07333333  0.00666667  0.00666667  0.00666667  0.00666667  0.00666667\n",
      "  0.87333333  0.00666667  0.00666667  0.00666667]\n",
      "\n",
      "Joke: Q. Did you hear about the dyslexic devil worshiper? \n",
      "<P>\n",
      "A. He sold his soul to Santa.\n",
      "\n",
      "Doc_topic:[ 0.34        0.00666667  0.27333333  0.00666667  0.00666667  0.00666667\n",
      "  0.07333333  0.27333333  0.00666667  0.00666667]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shows topics at which the IDs belong.\n",
    "doc_topic = lda_model.doc_topic_\n",
    "for i in range(6,8):\n",
    "    print \"Joke: {}\".format(jokes[i])\n",
    "    print \"\"\n",
    "    print \"Doc_topic:{}\".format(doc_topic[i])\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Pearson_jokes = pd.DataFrame(index = range(1,97),columns = range(1,97))\n",
    "cont = 1\n",
    "for item1 in range(1,97):\n",
    "    for item2 in range(1,97)[cont:]:\n",
    "        Pearson_jokes[item1][item2]=pearsonr(doc_topic[item1],doc_topic[item2])[0]\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.113262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.0729681</td>\n",
       "      <td>0.0118106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.00999327</td>\n",
       "      <td>0.00555761</td>\n",
       "      <td>-0.0473207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.0159041</td>\n",
       "      <td>-0.0316496</td>\n",
       "      <td>-0.0534512</td>\n",
       "      <td>-0.0590373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1           2          3          4    5    6    7    8    9    10  \\\n",
       "1         NaN         NaN        NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2   -0.113262         NaN        NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3  -0.0729681   0.0118106        NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4 -0.00999327  0.00555761 -0.0473207        NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "5  -0.0159041  -0.0316496 -0.0534512 -0.0590373  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "  ...    87   88   89   90   91   92   93   94   95   96  \n",
       "1 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "5 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pearson_jokes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same prediction algorithms as before are used in this case to test the performance of the content based approach. As results show, for this problem the content based approach yields poorer results. However, it would be expectalbe that an improvement should be noticed for this case, when using the whole original dataset, as I just took a subsample due to computational time requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_mat_content_based_bias_std = predition_matrix_item_based(predict_rating_bias_std_item_based, test_items, Pearson_jokes, training_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results after topic modeling with 50 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.685\n",
      "NMAE: 0.184\n"
     ]
    }
   ],
   "source": [
    "mae_content_based_bias_std = mae_item_based(pred_mat_content_based_bias_std)\n",
    "print \"MAE: {}\".format(round(mae_content_based_bias_std,3))\n",
    "print \"NMAE: {}\".format(round(mae_content_based_bias_std/20,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results after topic modeling with 10 topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.628\n",
      "NMAE: 0.181\n"
     ]
    }
   ],
   "source": [
    "mae_content_based_bias_std = mae_item_based(pred_mat_content_based_bias_std)\n",
    "print \"MAE: {}\".format(round(mae_content_based_bias_std,3))\n",
    "print \"NMAE: {}\".format(round(mae_content_based_bias_std/20,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**30 +2**30 +2**30+2**30 ==2**32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
